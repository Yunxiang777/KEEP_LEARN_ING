<!doctype html>
<html lang="zh-Hant">

<head>
  <meta charset="utf-8">
  <title>ECMAScript / 編碼 / Buffer 說明</title>
</head>

<body>

  <h1>ECMAScript、JavaScript、Node.js 與相關概念整理</h1>

  <section>
    <h2>ECMAScript 與實作</h2>
    <p>
      <strong>ECMAScript（簡稱 ES）</strong> 是一種標準，不是程式語言。<br>
      <strong>JavaScript</strong> 是 ECMAScript 的一種實作，實現了 ECMAScript 標準並在瀏覽器中提供瀏覽器特有的 API（例如 DOM API）。<br>
      <strong>Node.js</strong> 也是 ECMAScript 的一種實作，實現了 ECMAScript 標準並提供 Node.js 的 API（例如 <code>fs</code> 模組）。
    </p>

    <p>以「汽車」類比：</p>
    <ul>
      <li>ECMAScript = 汽車設計圖標準</li>
      <li>JavaScript = Toyota 根據設計圖製造的車</li>
      <li>Node.js = Tesla 根據同樣設計圖，但改成電動車版本</li>
    </ul>
  </section>

  <section>
    <h2>什麼是 ES5 和 ES6？</h2>
    <p>ES5 和 ES6 是 ECMAScript 標準的不同版本。</p>
  </section>

  <section>
    <h2>Buffer 是甚麼？</h2>
    <p>
      Buffer 是 Node.js 用來處理二進位資料的類別。在 JavaScript 裡，字串內部通常用 UTF-16 表示，而 Buffer 則以 <em>位元組（byte）</em> 為單位來儲存資料。Buffer
      常用於檔案讀寫、網路傳輸等需要操作二進位資料的情況。
    </p>
  </section>

  <section>
    <h2>Unicode 與 UTF-16 的關係</h2>
    <p>
      <strong>Unicode</strong> 是一個字元編碼標準，為全球所有文字和符號分配「唯一的編碼」。<br>
      <strong>UTF-16</strong> 是實現 Unicode 的一種具體編碼方式。
    </p>
  </section>

  <hr>

  <section>
    <h2>基礎背景說明（逐步講解）</h2>

    <section>
      <h2>Buffer 是甚麼？</h2>
      <p>
        Buffer 是 Node.js 用來處理二進位資料的類別。在 JavaScript 裡，字串內部通常用 UTF-16 表示，而 Buffer 則以 <em>位元組（byte）</em> 為單位來儲存資料。Buffer
        常用於檔案讀寫、網路傳輸等需要操作二進位資料的情況。
      </p>
    </section>

    <section>
      <h2>Unicode 與 UTF-16 的關係</h2>
      <p>
        <strong>Unicode</strong> 是一個字元編碼標準，為全球所有文字和符號分配「唯一的編碼」。<br>
        <strong>UTF-16</strong> 是實現 Unicode 的一種具體編碼方式。
      </p>
    </section>

    <h3>🧠 一、電腦只能看懂「數字（位元）」</h3>
    <p>對電腦而言，世界只有 0 和 1。字母、漢字、符號都要先「變成數字」，然後再「變成位元」才能儲存或顯示。例如：<code>A → 65 → 01000001（二進位）</code></p>

    <h3>🏗️ 二、最早只有 ASCII（美國標準）</h3>
    <p>在 1960～1970 年代，電腦只支援英文。ASCII 使用 1 byte（8 bits），可表示 0~127 共 128 個符號。</p>

    <table>
      <caption>ASCII 範例</caption>
      <thead>
        <tr>
          <th>字元</th>
          <th>數字</th>
          <th>二進位</th>
          <th>說明</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>A</td>
          <td>65</td>
          <td>01000001</td>
          <td>英文字母</td>
        </tr>
        <tr>
          <td>B</td>
          <td>66</td>
          <td>01000010</td>
          <td>英文字母</td>
        </tr>
        <tr>
          <td>a</td>
          <td>97</td>
          <td>01100001</td>
          <td>英文字母</td>
        </tr>
      </tbody>
    </table>

    <h3>🌏 三、問題：那中文、日文、希伯來文怎辦？</h3>
    <p>
      ASCII 不夠表示其他語言，各國因此發明不同編碼（如 Big5、Shift-JIS、GB2312）導致混亂——同一組數字在不同編碼下會代表不同字。
    </p>

    <table>
      <caption>不同編碼下相同數字的顯示差異（示意）</caption>
      <thead>
        <tr>
          <th>編碼系統</th>
          <th>數字</th>
          <th>顯示結果</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Big5</td>
          <td>0xA4A4</td>
          <td>「你」</td>
        </tr>
        <tr>
          <td>GB2312</td>
          <td>0xA4A4</td>
          <td>「啊」</td>
        </tr>
        <tr>
          <td>Shift-JIS</td>
          <td>0xA4A4</td>
          <td>亂碼</td>
        </tr>
      </tbody>
    </table>

    <h3>🌐 四、Unicode 的出現：統一編號系統</h3>
    <p>Unicode 的目標：為全世界所有文字配置一個「全球唯一的代碼」。</p>

    <table>
      <caption>Unicode 範例</caption>
      <thead>
        <tr>
          <th>字元</th>
          <th>Unicode 碼點（Code Point）</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>A</td>
          <td>U+0041</td>
        </tr>
        <tr>
          <td>中</td>
          <td>U+4E2D</td>
        </tr>
        <tr>
          <td>😊</td>
          <td>U+1F60A</td>
        </tr>
      </tbody>
    </table>

    <p>
      注意：<strong>U+0041</strong> 是抽象的字元代號，不代表實際的位元資料；它只是「給這個符號一個唯一的編號」。
    </p>

    <h3>💾 五、UTF 系列的目的：把 Unicode「轉成」實際位元</h3>
    <p>
      電腦要儲存、傳輸資料，需要把 Unicode 碼點轉換成 bytes，這就是 UTF（Unicode Transformation Format）的工作。不同
      UTF（UTF-8、UTF-16、UTF-32）會把同一個碼點轉成不同的 bytes 表示。
    </p>

    <p>範例（字元 A）：</p>
    <ul>
      <li>Unicode 定義：A = U+0041</li>
      <li>UTF-16 編碼：U+0041 → 00 41（兩個 bytes）</li>
      <li>UTF-8 編碼：U+0041 → 41（一個 byte）</li>
    </ul>

    <p>因此在電腦底層，</p>
    <pre><code>UTF-16 的 A：00000000 01000001
UTF-8 的 A：01000001</code></pre>

    <h3>⚙️ 六、為什麼需要 U+0041 這種符號格式？</h3>
    <p>
      因為 Unicode 碼點是抽象定義，不綁定任何實際的編碼方式。好處包含統一、互通以及方便維護。簡單說：<strong>U+0041 是字元 A 的身份證號碼，UTF-8/UTF-16
        是如何把這個人存進電腦裡的方式。</strong>
    </p>

    <h3>🧩 七、完整流程圖（概念層 → 編碼層 → 顯示層）</h3>
    <p>概念層：</p>
    <pre><code>"A" → Unicode code point: U+0041 ← (全世界統一的代號)</code></pre>

    <p>編碼層：</p>
    <pre><code>UTF-8 → 0x41 → 01000001
UTF-16 → 0x0041 → 00000000 01000001
UTF-32 → 0x00000041 → 00000000 00000000 00000000 01000001</code></pre>

    <p>顯示層：螢幕顯示 "A"</p>
  </section>

  <hr>

  <section>
    <h2>Node.js Buffer 範例解析</h2>

    <p>你提供的程式碼：</p>

    <pre><code>let buf = Buffer.from('hello');
console.log(buf);</code></pre>

    <p>你在命令列看到的輸出（正確應為）：</p>

    <pre><code>&lt;Buffer 68 65 6c 6c 6f&gt;</code></pre>

    <p>（你貼的 <code>&lt;Buffer 68 65 6c 6c 6f 77&gt;</code> 裡的最後 <code>77</code> 很可能是多打一個字母，正確只有五個位元組）</p>

    <h3>發生了什麼？（逐步說明）</h3>
    <ol>
      <li><strong>'hello' 是一個 JavaScript 字串</strong> — JavaScript 字串內部通常以 UTF-16 表示。</li>
      <li><strong>Buffer.from('hello')</strong> — Node.js 會把字串轉成 UTF-8 編碼的 bytes，然後建立一個 <code>Buffer</code>
        物件（相當於位元組陣列）。</li>
      <li><strong>console.log(buf)</strong> — Node.js 以十六進位（hex）格式顯示每個位元組，所以看到
        <code>&lt;Buffer 68 65 6c 6c 6f&gt;</code>。
      </li>
    </ol>

    <h3>逐字對照分析</h3>
    <table>
      <caption>字元 → Unicode 碼點 → UTF-8（hex） → Buffer 內容</caption>
      <thead>
        <tr>
          <th>字元</th>
          <th>Unicode 碼點</th>
          <th>UTF-8（十六進位）</th>
          <th>Buffer 內容</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>h</td>
          <td>U+0068</td>
          <td>68</td>
          <td>68</td>
        </tr>
        <tr>
          <td>e</td>
          <td>U+0065</td>
          <td>65</td>
          <td>65</td>
        </tr>
        <tr>
          <td>l</td>
          <td>U+006C</td>
          <td>6C</td>
          <td>6C</td>
        </tr>
        <tr>
          <td>l</td>
          <td>U+006C</td>
          <td>6C</td>
          <td>6C</td>
        </tr>
        <tr>
          <td>o</td>
          <td>U+006F</td>
          <td>6F</td>
          <td>6F</td>
        </tr>
      </tbody>
    </table>

    <p>所以結果：<code>&lt;Buffer 68 65 6c 6c 6f&gt;</code></p>

    <h3>為何顯示 68 而不是 104？</h3>
    <p>
      因為 <code>0x68</code>（十六進位）等於 <code>104</code>（十進位）。Node.js 為了可讀性，用十六進位來顯示位元組值；<code>0x68</code> 對應字母 'h' 的
      ASCII／UTF-8 編碼值（十進位 104）。
    </p>

    <h3>驗證與補充範例</h3>
    <pre><code>let buf = Buffer.from('hello');
console.log(buf.toString('utf8')); // hello
console.log(buf.toString('hex'));  // 68656c6c6f</code></pre>

    <p>整個關係總結：</p>
    <pre><code>JavaScript 字串 "hello"
↓ (內部是 UTF-16)
Buffer.from("hello")
↓ (轉成 UTF-8)
Buffer = &lt;68 65 6C 6C 6F&gt;
↓
顯示時以十六進位格式輸出</code></pre>

    <h3>簡單總結表</h3>
    <table>
      <thead>
        <tr>
          <th>概念</th>
          <th>說明</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Buffer</td>
          <td>Node.js 的二進位資料容器，類似 byte array</td>
        </tr>
        <tr>
          <td>'hello'</td>
          <td>JavaScript 字串（內部 UTF-16）</td>
        </tr>
        <tr>
          <td>Buffer.from('hello')</td>
          <td>將字串轉成 UTF-8 bytes</td>
        </tr>
        <tr>
          <td>&lt;Buffer 68 65 6c 6c 6f&gt;</td>
          <td>顯示每個 byte 的十六進位值（對應 h e l l o）</td>
        </tr>
      </tbody>
    </table>

  </section>

  <hr>

  <section>
    <h2>補充：UTF-8 的位元組數（簡一句話）</h2>
    <p>
      UTF-8 用 1～4 個 bytes 來表示一個 Unicode 字元：<br>
      英文（U+0000 ~ U+007F）= 1 byte；U+0080 ~ U+07FF = 2 bytes；U+0800 ~ U+FFFF = 3 bytes（多數亞洲文字）；U+10000 ~ U+10FFFF = 4
      bytes（emoji、罕見字、特殊符號）。
    </p>

    <table>
      <caption>UTF-8 字元範圍與位元組數</caption>
      <thead>
        <tr>
          <th>字元範圍（Unicode 碼點）</th>
          <th>位元組數（Bytes）</th>
          <th>說明</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>U+0000 ~ U+007F</td>
          <td>1</td>
          <td>英文、數字、基本符號（與 ASCII 完全相同）</td>
        </tr>
        <tr>
          <td>U+0080 ~ U+07FF</td>
          <td>2</td>
          <td>拉丁擴充、希臘文、阿拉伯文等</td>
        </tr>
        <tr>
          <td>U+0800 ~ U+FFFF</td>
          <td>3</td>
          <td>多數亞洲文字（如中文、日文、韓文）</td>
        </tr>
        <tr>
          <td>U+10000 ~ U+10FFFF</td>
          <td>4</td>
          <td>emoji、罕見字、特殊符號</td>
        </tr>
      </tbody>
    </table>
  </section>

  <hr>

  <section>
    <h2>若要進一步示範（可選）</h2>
    <p>
      你可以比較不同編碼下的 Buffer，例如：
    </p>
    <pre><code>Buffer.from('hello', 'utf8')
Buffer.from('hello', 'utf16le')</code></pre>
    <p>第一個會產生 5 bytes（UTF-8），第二個會產生 10 bytes（UTF-16LE，每字佔 2 bytes）。</p>
  </section>

  <footer>
    <p>—— 結束 ——</p>
  </footer>

</body>

</html>